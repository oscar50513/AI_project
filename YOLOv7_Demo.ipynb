{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b855003a",
   "metadata": {
    "id": "b855003a",
    "outputId": "258474f9-f086-4c3e-8c71-7eaef0146b1f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attempt_load\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoadStreams, LoadImages\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n\u001b[0;32m     12\u001b[0m     scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "from pathlib import Path\n",
    "from numpy import random\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62050f",
   "metadata": {
    "id": "bf62050f"
   },
   "outputs": [],
   "source": [
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    shape = img.shape[:2]  \n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "    \n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1]) \n",
    "    if not scaleup:  r = min(r, 1.0) \n",
    "\n",
    "    ratio = r, r \n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1] \n",
    "    if auto:  \n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  \n",
    "    elif scaleFill:  \n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  \n",
    "\n",
    "    dw /= 2; dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  \n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  \n",
    "    return img, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf497a",
   "metadata": {
    "id": "42bf497a"
   },
   "outputs": [],
   "source": [
    "# opt字典: 儲存參數\n",
    "opt  = { \"weights\": \"weights/yolov7-tiny.pt\",  # 權重模型位置\n",
    "         \"yaml\"   : \"data/coco.yaml\",     # 標籤名稱\n",
    "         \"img-size\": 640,                 # 輸入影像大小\n",
    "         \"conf-thres\": 0.5,               # 預測的置信度臨界值 \n",
    "         \"iou-thres\" : 0.5,               # 非最大抑制的IoU臨界值\n",
    "         \"device\" : 'CPU',  # 設備是否(不)啟用GPU(CPU) 0 or cpu\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07170ecf",
   "metadata": {
    "id": "07170ecf",
    "outputId": "574e6c6a-4015-4e79-9043-a19c390fe3dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIoT\\.conda\\envs\\YOLOv7\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    weights, imgsz = opt['weights'], opt['img-size']\n",
    "    device = select_device(opt['device'])\n",
    "    half = device.type != 'cpu'\n",
    "    model = attempt_load(weights, map_location=device)  \n",
    "    stride = int(model.stride.max())  \n",
    "    imgsz = check_img_size(imgsz, s=stride)  \n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
    "    torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab94c2",
   "metadata": {
    "id": "77ab94c2"
   },
   "outputs": [],
   "source": [
    "def yolov7_inference(img0):\n",
    "    with torch.no_grad():\n",
    "        img = letterbox(img0, imgsz, stride=stride)[0]\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  \n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.from_numpy(img).to(device).float() / 255.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "        pred = model(img, augment= False)[0]\n",
    "        pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], agnostic= False)\n",
    "\n",
    "        for i, det in enumerate(pred):\n",
    "            s = '' ; s += '%gx%g ' % img.shape[2:]  \n",
    "            if len(det):\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  \n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  \n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                    plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "    torch.cuda.empty_cache()\n",
    "    return img0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcade8",
   "metadata": {
    "id": "2ffcade8"
   },
   "outputs": [],
   "source": [
    "source_image_path = 'inference/images/horses.jpg'\n",
    "img = cv2.imread(source_image_path)\n",
    "img = yolov7_inference(img)\n",
    "cv2.imshow('My Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
